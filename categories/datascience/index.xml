<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dataScience on Data Scientist Hiroki&#39;s Blog</title>
    <link>https://dshiroki.com/categories/datascience/</link>
    <description>Recent content in dataScience on Data Scientist Hiroki&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 24 Aug 2024 14:04:46 +0900</lastBuildDate><atom:link href="https://dshiroki.com/categories/datascience/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>機械学習の基礎 〜ベイズの定理 その2〜</title>
      <link>https://dshiroki.com/datascience/20240824/</link>
      <pubDate>Sat, 24 Aug 2024 14:04:46 +0900</pubDate>
      
      <guid>https://dshiroki.com/datascience/20240824/</guid>
      <description>機械学習の基礎 〜ベイズの定理〜 2024年も8月後半、まだまだ残暑厳しいですね🌞
こんにちは、データサイエンティストひろきです。
前回に引き続き、ベイズの定理の具体例を紹介します。
ベイズの定理 $$\begin{align*} P(A|B) = \frac{P(B|A)}{P(B)}\cdot P(A) \
\end{align*}$$
$$\begin{align*} P(A|B)&amp;amp;:事後分布 (posterior)\\
P(B|A)/P(B)&amp;amp;:尤度 (likely hood)\\
P(A)&amp;amp;:事前分布 (prior)\\
\end{align*}$$
事前分布をlikely hood関数で更新し、事後分布を得る。これをベイズ更新と呼びます。
ベイズの定理の応用例：沈没船を探せ     沈没船をある海域から探す時、見つかる確率をベイズの定理を使って考えてみましょう。
まず下記事象を考えます。
$$\begin{align*} &amp;amp;A={ある海域に船が沈んでいる} \\
&amp;amp;B={船を探して実際に船が見つかる}\\
&amp;amp;A^c={ある海域に船が沈んでいない} \\
&amp;amp;B^c={船を探して実際に船が見つからない}\
\end{align*}$$
そして、下記確率を考えてみます。
$$\begin{align*} &amp;amp;p=P(A) :ある海域に船が沈んでいる確率(主観的に決める) \\
&amp;amp;q=P(B|A):ある海域に船が沈んでいて、船を探して実際に船が見つかる確率(捜査船の能力)\\
\end{align*}$$
この時、ある海域を探して見つからなかったけれども、実はその海域に船が沈んでいる確率 $$\begin{align*} P(A|B^c)\\
\end{align*}$$ を求めてみましょう。
まずはベイズの定理より $$\begin{align*} P(A|B^c)&amp;amp;=\frac{P(A \land B^c)}{P(B^c)}\\
&amp;amp;=\frac{P(B^c|A) \cdot P(A)}{P(B^c)}\\
\end{align*}$$
これをpとqで表したいので、P(A)があからさまな形で出てくるように分母を変形し、
ベイズの定理の一部を適用すると、
$$\begin{align*} P(B^c)&amp;amp;=P(A \land B^c)+P(A^c \land B^c)\\
&amp;amp;=P(B^c|A)\cdot P(A)+P(B^c|A^c)\cdot P(A^c)\\</description>
    </item>
    
    <item>
      <title>機械学習の基礎 〜ベイズの定理 その1〜</title>
      <link>https://dshiroki.com/datascience/20240816/</link>
      <pubDate>Fri, 16 Aug 2024 14:04:46 +0900</pubDate>
      
      <guid>https://dshiroki.com/datascience/20240816/</guid>
      <description>機械学習の基礎 〜ベイズの定理〜 2024年も8月になりました。
暑いですね〜💦 この暑い夏、確率論や機械学習を活用し、涼しくさらっと乗り切りたい🌞
こんにちは、データサイエンティストひろきです。
ようやくデータサイエンティストらしく、機械学習をテーマにブログを書くことにします。
今回は条件付き確率について、
その前に普通の確率の話から、ロールプレイングゲームの勇者を例にお話しします。　普通の確率 勇者が宝箱📦を2つ見つけました。
一方は宝石💎、もう一方にはうんこ💩が入っています。
どちらかの箱📦を選ぶ必要があります。
箱📦の中身が宝石💎である確率は？　はい、1/2の確率で、宝箱には宝石💎が入っていますね。
$$\begin{align*} P(📦=💎)=\frac{💎}{💎 or 💩}=\frac{1}{2} \
\end{align*}$$
と書くことにします。　 では、うんこ💩を選んでしまう確率は？
$$\begin{align*} P(📦=💩)=\frac{💩}{💎 or 💩}=\frac{1}{2} \
\end{align*}$$
1/2ですね。 つまり、確率P=(probability)というのは、対象となる事象/全体事象です。
$$\begin{align*} 確率P=\frac{対象となる事象}{全体事象} \
\end{align*}$$
条件付き確率 次に、勇者は魔法を使って、箱を開ける前にどちらの箱に宝石💎が入っているかどうかを当てることができるとします。
 でも、勇者の魔法は未熟で、確率1/4で判定ミスをします。
さて、今、勇者は魔法🪄をかけました。
そして、勇者は言いました。
「右の箱に宝石💎が入っている‼️」
 はい、ここまでが前提条件です。
この時、魔法🪄が外れてうんこ💩を選んでしまう確率は？
つまり、
魔法🪄をかけて、「右の箱に宝石💎が入っている‼️」と勇者が言っている条件の元、 箱📦の中身はうんこ💩である確率を
$$\begin{align*} P(📦=💩|🪄=💎) = \frac{P(📦=💩 and 🪄=💎)}{P(🪄=💎)}\
\end{align*}$$
と表します。
これが求めたい確率です。　まず、分母の $$\begin{align*} P(🪄=💎)\
\end{align*}$$
を求めます。
魔法🪄が当たる場合と、外れる場合に場合分けして考えます。
 魔法🪄が当たる場合：「右の箱に宝石💎が入っている‼️」と言って、本当に箱📦に宝石💎が入っていた場合 魔法🪄が外れる場合：「右の箱に宝石💎が入っている‼️」と言って、箱📦にはうんこ💩が入っていた場合  1. 魔法🪄が当たる場合　 勇者の魔法🪄が当たる確率、</description>
    </item>
    
  </channel>
</rss>
